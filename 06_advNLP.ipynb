{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_advNLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLQQ-WLfTRzB",
        "colab_type": "text"
      },
      "source": [
        "### Neural Machine Translation using Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkYJ5snBS2cE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96b0850e-3e05-4e49-fe6e-b27a6068320d"
      },
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras.layers import (Input,LSTM,GRU,Dense,\n",
        "                          Embedding,Bidirectional,RepeatVector,\n",
        "                          Concatenate,Activation,Dot,Lambda)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras.backend as K"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U375mCZTTX-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to do softmax over time\n",
        "def softmax_over_time(x):\n",
        "  assert(K.ndim(x) > 2)\n",
        "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
        "  s = K.sum(e, axis=1, keepdims=True)\n",
        "  return e/s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lHUQxAcUsYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# config variables\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "LATENT_DIM = 256\n",
        "LATENT_DIM_DECODER = 256\n",
        "NUM_SAMPLES = 10000\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da1kQMSZVQy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_texts = [] # sentence in original language\n",
        "target_texts = [] # sentence in target language\n",
        "target_texts_inputs = [] # sentence in target language offset by 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAOS5AsrVXIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d23fda02-ee24-4d8f-9b4e-6cae7b4753e4"
      },
      "source": [
        "# load in the data\n",
        "t = 0\n",
        "for line in open('hin.txt'):\n",
        "  t+=1\n",
        "  if t>NUM_SAMPLES:\n",
        "    break\n",
        "  # input and target are seperated by '\\t'\n",
        "  if '\\t' not in line:\n",
        "    continue\n",
        "  input_text, translation = line.split('\\t')\n",
        "  target_text = translation + ' <eos>'\n",
        "  target_text_input = '<sos> ' + translation\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "  target_texts_inputs.append(target_text_input)\n",
        "print('num samples:',len(input_texts))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples: 2808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSiCip5bVz-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer_inputs.fit_on_texts(input_texts)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_IvjfRyV_PJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "79a6ea54-ac11-42b7-de8c-2e03ea932cca"
      },
      "source": [
        "# word to index mapping for input language\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "print('Found %s unique input tokens.'%len(word2idx_inputs))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2388 unique input tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tf9YwGRWhkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# max length input seq\n",
        "max_len_input = max(len(s) for s in input_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYGKvDM7WCTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize the outputs\n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs)\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ic4lx7_WHWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a267fcc-7059-4d55-8ef6-f84c2caa2647"
      },
      "source": [
        "# word to index mapping for output language\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "print('Found %s unique output tokens.'%len(word2idx_outputs))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3150 unique output tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0QuvS2EWKNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words_output = len(word2idx_outputs)+1\n",
        "# max length output seq\n",
        "max_len_target = max(len(s) for s in target_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u69mBx5CWUfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2c5b6afe-edec-4ebf-8387-1ce560c62626"
      },
      "source": [
        "# padding the sequences\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
        "print('Encoder data shape:',encoder_inputs.shape)\n",
        "\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
        "print('Decoder data shape:',decoder_inputs.shape)\n",
        "\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder data shape: (2808, 22)\n",
            "Decoder data shape: (2808, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaBGBku0WbC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "9f7ccddd-498a-44c2-ddcc-bc038dc81845"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-10 16:26:46--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-08-10 16:26:47--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-08-10 16:26:47--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  38.0MB/s    in 22s     \n",
            "\n",
            "2019-08-10 16:27:09 (37.2 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4iaFwxWWpUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "fe304e6c-10b5-4302-9d03-c29a9190285a"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA0cyMi0WrMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd0f8d73-9040-4fdb-d28a-ba38777d5163"
      },
      "source": [
        "# loading pre-trained word vectors\n",
        "word2vec = {}\n",
        "with open('glove.6B.%sd.txt'%EMBEDDING_DIM) as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:],dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.'%len(word2vec))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NromsHVNWtO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare embedding matrix\n",
        "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs)+1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word2idx_inputs.items():\n",
        "  if i < MAX_NUM_WORDS:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtseteWjWvRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating embedding layer\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_len_input,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytyd1E-5W-pM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_targets_one_hot = np.zeros((len(input_texts),\n",
        "                                   max_len_target,\n",
        "                                   num_words_output),dtype='float32')\n",
        "for i,d in enumerate(decoder_targets):\n",
        "  for t,word in enumerate(d):\n",
        "    decoder_targets_one_hot[i, t, word] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN-hJRNBXK55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model\n",
        "# setup the encoder\n",
        "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = Bidirectional(LSTM(LATENT_DIM, return_sequences=True, dropout=0.5))\n",
        "encoder_outputs = encoder(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArYt6BpJYDIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup the decoder\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
        "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k279HGgRYviP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Attention layer\n",
        "attn_repeat_layer = RepeatVector(max_len_input)\n",
        "attn_concat_layer = Concatenate(axis=-1)\n",
        "attn_dense1 = Dense(10, activation='tanh')\n",
        "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
        "attn_dot = Dot(axes=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOjtFMZkZfnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_step_attention(h, st_1):\n",
        "  # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
        "  # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
        " \n",
        "  # copy s(t-1) Tx times\n",
        "  # now shape = (Tx, LATENT_DIM_DECODER)\n",
        "  st_1 = attn_repeat_layer(st_1)\n",
        "\n",
        "  # Concatenate all h(t)'s with s(t-1)\n",
        "  # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
        "  x = attn_concat_layer([h, st_1])\n",
        "\n",
        "  # Neural net first layer\n",
        "  x = attn_dense1(x)\n",
        "\n",
        "  # Neural net second layer with special softmax over time\n",
        "  alphas = attn_dense2(x)\n",
        "\n",
        "  # \"Dot\" the alphas and the h's\n",
        "  # Remember a.dot(b) = sum over a[t] * b[t]\n",
        "  context = attn_dot([alphas, h])\n",
        "\n",
        "  return context"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZMlCt7LbK2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decoder after attention\n",
        "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auai03zdb_ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
        "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
        "context_last_word_concat_layer = Concatenate(axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KClaJ0HMcd6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# s, c will be re-assigned in each iteration of the loop\n",
        "s = initial_s\n",
        "c = initial_c\n",
        "\n",
        "# collect outputs in a list at first\n",
        "outputs = []\n",
        "for t in range(max_len_target): # Ty times\n",
        "  # get the context using attention\n",
        "  context = one_step_attention(encoder_outputs, s)\n",
        "\n",
        "  # we need a different layer for each time step\n",
        "  selector = Lambda(lambda x: x[:, t:t+1])\n",
        "  xt = selector(decoder_inputs_x)\n",
        "  \n",
        "  # combine \n",
        "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
        "\n",
        "  # pass the combined [context, last word] into the LSTM\n",
        "  # along with [s, c]\n",
        "  # get the new [s, c] and output\n",
        "  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
        "\n",
        "  # final dense layer to get next word prediction\n",
        "  decoder_outputs = decoder_dense(o)\n",
        "  outputs.append(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsGmlxp3d_95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'outputs' is now a list of length Ty\n",
        "# each element is of shape [batch_size, output_vocab_size]\n",
        "# therefore if we simply stack all the outputs into 1 tensor\n",
        "# it would be of shape TxNxD\n",
        "# we would like it to be of shape NxTxD\n",
        "\n",
        "# so we stack and transpose\n",
        "def stack_and_transpose(x):\n",
        "  x = K.stack(x)\n",
        "  x = K.permute_dimensions(x, pattern=(1, 0, 2))\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BamvKMJ1hh0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making it a layer\n",
        "stacker = Lambda(stack_and_transpose)\n",
        "outputs = stacker(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB1tfVUyhsin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the model\n",
        "model = Model(inputs=[encoder_inputs_placeholder,\n",
        "                      decoder_inputs_placeholder,\n",
        "                      initial_s,\n",
        "                      initial_c],\n",
        "              outputs=outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caxYrtTUh-i9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9IC1ildigpW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa183879-9516-413f-9b84-c6b88792462c"
      },
      "source": [
        "z = np.zeros((len(encoder_inputs), LATENT_DIM_DECODER)) # initial [s, c]\n",
        "r = model.fit(\n",
        "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2\n",
        ")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2246 samples, validate on 562 samples\n",
            "Epoch 1/100\n",
            "2246/2246 [==============================] - 45s 20ms/step - loss: 1.0327 - acc: 0.8094 - val_loss: 2.5511 - val_acc: 0.6458\n",
            "Epoch 2/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.9837 - acc: 0.8128 - val_loss: 2.5119 - val_acc: 0.6482\n",
            "Epoch 3/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.9544 - acc: 0.8161 - val_loss: 2.5399 - val_acc: 0.6471\n",
            "Epoch 4/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.9247 - acc: 0.8184 - val_loss: 2.5919 - val_acc: 0.6488\n",
            "Epoch 5/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.8977 - acc: 0.8206 - val_loss: 2.5595 - val_acc: 0.6497\n",
            "Epoch 6/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.8702 - acc: 0.8241 - val_loss: 2.5636 - val_acc: 0.6506\n",
            "Epoch 7/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.8455 - acc: 0.8265 - val_loss: 2.5711 - val_acc: 0.6524\n",
            "Epoch 8/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.8202 - acc: 0.8305 - val_loss: 2.5758 - val_acc: 0.6530\n",
            "Epoch 9/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.7950 - acc: 0.8336 - val_loss: 2.5542 - val_acc: 0.6535\n",
            "Epoch 10/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.7695 - acc: 0.8373 - val_loss: 2.5769 - val_acc: 0.6508\n",
            "Epoch 11/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.7471 - acc: 0.8406 - val_loss: 2.5841 - val_acc: 0.6508\n",
            "Epoch 12/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.7221 - acc: 0.8463 - val_loss: 2.6028 - val_acc: 0.6534\n",
            "Epoch 13/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.6989 - acc: 0.8500 - val_loss: 2.6196 - val_acc: 0.6504\n",
            "Epoch 14/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.6758 - acc: 0.8538 - val_loss: 2.6009 - val_acc: 0.6523\n",
            "Epoch 15/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.6539 - acc: 0.8588 - val_loss: 2.6346 - val_acc: 0.6539\n",
            "Epoch 16/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.6309 - acc: 0.8630 - val_loss: 2.6263 - val_acc: 0.6523\n",
            "Epoch 17/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.6114 - acc: 0.8676 - val_loss: 2.6211 - val_acc: 0.6554\n",
            "Epoch 18/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.5885 - acc: 0.8718 - val_loss: 2.6327 - val_acc: 0.6556\n",
            "Epoch 19/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.5690 - acc: 0.8772 - val_loss: 2.6660 - val_acc: 0.6519\n",
            "Epoch 20/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.5492 - acc: 0.8812 - val_loss: 2.6395 - val_acc: 0.6536\n",
            "Epoch 21/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.5300 - acc: 0.8860 - val_loss: 2.6652 - val_acc: 0.6558\n",
            "Epoch 22/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.5134 - acc: 0.8888 - val_loss: 2.6710 - val_acc: 0.6540\n",
            "Epoch 23/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.4933 - acc: 0.8937 - val_loss: 2.6630 - val_acc: 0.6534\n",
            "Epoch 24/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.4735 - acc: 0.8985 - val_loss: 2.6509 - val_acc: 0.6555\n",
            "Epoch 25/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.4587 - acc: 0.9025 - val_loss: 2.6653 - val_acc: 0.6567\n",
            "Epoch 26/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.4403 - acc: 0.9068 - val_loss: 2.6955 - val_acc: 0.6540\n",
            "Epoch 27/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.4240 - acc: 0.9090 - val_loss: 2.7004 - val_acc: 0.6541\n",
            "Epoch 28/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.4063 - acc: 0.9137 - val_loss: 2.6765 - val_acc: 0.6548\n",
            "Epoch 29/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.3898 - acc: 0.9183 - val_loss: 2.7023 - val_acc: 0.6567\n",
            "Epoch 30/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.3753 - acc: 0.9221 - val_loss: 2.7051 - val_acc: 0.6534\n",
            "Epoch 31/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.3591 - acc: 0.9260 - val_loss: 2.7284 - val_acc: 0.6549\n",
            "Epoch 32/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.3447 - acc: 0.9285 - val_loss: 2.7165 - val_acc: 0.6518\n",
            "Epoch 33/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.3290 - acc: 0.9328 - val_loss: 2.7281 - val_acc: 0.6550\n",
            "Epoch 34/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.3164 - acc: 0.9344 - val_loss: 2.7510 - val_acc: 0.6559\n",
            "Epoch 35/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.3033 - acc: 0.9386 - val_loss: 2.7485 - val_acc: 0.6551\n",
            "Epoch 36/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.2911 - acc: 0.9409 - val_loss: 2.7450 - val_acc: 0.6540\n",
            "Epoch 37/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.2765 - acc: 0.9447 - val_loss: 2.7480 - val_acc: 0.6563\n",
            "Epoch 38/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.2649 - acc: 0.9474 - val_loss: 2.7487 - val_acc: 0.6553\n",
            "Epoch 39/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.2536 - acc: 0.9496 - val_loss: 2.7545 - val_acc: 0.6547\n",
            "Epoch 40/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.2417 - acc: 0.9531 - val_loss: 2.7791 - val_acc: 0.6561\n",
            "Epoch 41/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.2312 - acc: 0.9547 - val_loss: 2.7568 - val_acc: 0.6549\n",
            "Epoch 42/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.2211 - acc: 0.9572 - val_loss: 2.7911 - val_acc: 0.6558\n",
            "Epoch 43/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.2129 - acc: 0.9586 - val_loss: 2.7964 - val_acc: 0.6558\n",
            "Epoch 44/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.2005 - acc: 0.9616 - val_loss: 2.8227 - val_acc: 0.6562\n",
            "Epoch 45/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1914 - acc: 0.9635 - val_loss: 2.8059 - val_acc: 0.6554\n",
            "Epoch 46/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1819 - acc: 0.9661 - val_loss: 2.8171 - val_acc: 0.6562\n",
            "Epoch 47/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1742 - acc: 0.9675 - val_loss: 2.8235 - val_acc: 0.6540\n",
            "Epoch 48/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1659 - acc: 0.9700 - val_loss: 2.8365 - val_acc: 0.6564\n",
            "Epoch 49/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1557 - acc: 0.9723 - val_loss: 2.8390 - val_acc: 0.6523\n",
            "Epoch 50/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1496 - acc: 0.9734 - val_loss: 2.8180 - val_acc: 0.6547\n",
            "Epoch 51/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1420 - acc: 0.9747 - val_loss: 2.8469 - val_acc: 0.6556\n",
            "Epoch 52/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1347 - acc: 0.9758 - val_loss: 2.8578 - val_acc: 0.6536\n",
            "Epoch 53/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1281 - acc: 0.9779 - val_loss: 2.8658 - val_acc: 0.6547\n",
            "Epoch 54/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1214 - acc: 0.9785 - val_loss: 2.8883 - val_acc: 0.6535\n",
            "Epoch 55/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1162 - acc: 0.9795 - val_loss: 2.8813 - val_acc: 0.6558\n",
            "Epoch 56/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1113 - acc: 0.9805 - val_loss: 2.8882 - val_acc: 0.6564\n",
            "Epoch 57/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.1053 - acc: 0.9821 - val_loss: 2.9034 - val_acc: 0.6549\n",
            "Epoch 58/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0987 - acc: 0.9836 - val_loss: 2.9122 - val_acc: 0.6570\n",
            "Epoch 59/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0942 - acc: 0.9835 - val_loss: 2.9348 - val_acc: 0.6541\n",
            "Epoch 60/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0902 - acc: 0.9841 - val_loss: 2.9409 - val_acc: 0.6541\n",
            "Epoch 61/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0851 - acc: 0.9853 - val_loss: 2.9430 - val_acc: 0.6564\n",
            "Epoch 62/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0823 - acc: 0.9856 - val_loss: 2.9518 - val_acc: 0.6560\n",
            "Epoch 63/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0774 - acc: 0.9866 - val_loss: 2.9469 - val_acc: 0.6551\n",
            "Epoch 64/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0736 - acc: 0.9875 - val_loss: 2.9575 - val_acc: 0.6554\n",
            "Epoch 65/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0693 - acc: 0.9884 - val_loss: 2.9680 - val_acc: 0.6545\n",
            "Epoch 66/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0660 - acc: 0.9889 - val_loss: 2.9646 - val_acc: 0.6547\n",
            "Epoch 67/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0625 - acc: 0.9894 - val_loss: 2.9994 - val_acc: 0.6562\n",
            "Epoch 68/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0598 - acc: 0.9894 - val_loss: 2.9811 - val_acc: 0.6545\n",
            "Epoch 69/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0574 - acc: 0.9900 - val_loss: 3.0523 - val_acc: 0.6550\n",
            "Epoch 70/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0540 - acc: 0.9900 - val_loss: 3.0040 - val_acc: 0.6578\n",
            "Epoch 71/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0524 - acc: 0.9903 - val_loss: 3.0178 - val_acc: 0.6552\n",
            "Epoch 72/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0491 - acc: 0.9912 - val_loss: 3.0685 - val_acc: 0.6537\n",
            "Epoch 73/100\n",
            "2246/2246 [==============================] - 10s 5ms/step - loss: 0.0472 - acc: 0.9915 - val_loss: 3.0210 - val_acc: 0.6564\n",
            "Epoch 74/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0439 - acc: 0.9918 - val_loss: 3.0319 - val_acc: 0.6545\n",
            "Epoch 75/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0420 - acc: 0.9924 - val_loss: 3.0513 - val_acc: 0.6559\n",
            "Epoch 76/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0404 - acc: 0.9923 - val_loss: 3.0685 - val_acc: 0.6559\n",
            "Epoch 77/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0381 - acc: 0.9929 - val_loss: 3.0504 - val_acc: 0.6536\n",
            "Epoch 78/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0377 - acc: 0.9930 - val_loss: 3.0729 - val_acc: 0.6547\n",
            "Epoch 79/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0349 - acc: 0.9931 - val_loss: 3.0859 - val_acc: 0.6564\n",
            "Epoch 80/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0337 - acc: 0.9932 - val_loss: 3.1204 - val_acc: 0.6547\n",
            "Epoch 81/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0325 - acc: 0.9938 - val_loss: 3.1260 - val_acc: 0.6521\n",
            "Epoch 82/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0319 - acc: 0.9935 - val_loss: 3.1107 - val_acc: 0.6560\n",
            "Epoch 83/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0304 - acc: 0.9936 - val_loss: 3.1153 - val_acc: 0.6558\n",
            "Epoch 84/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0294 - acc: 0.9936 - val_loss: 3.1522 - val_acc: 0.6558\n",
            "Epoch 85/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0276 - acc: 0.9941 - val_loss: 3.1322 - val_acc: 0.6562\n",
            "Epoch 86/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0277 - acc: 0.9934 - val_loss: 3.1281 - val_acc: 0.6556\n",
            "Epoch 87/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0258 - acc: 0.9938 - val_loss: 3.1293 - val_acc: 0.6554\n",
            "Epoch 88/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0251 - acc: 0.9939 - val_loss: 3.1566 - val_acc: 0.6551\n",
            "Epoch 89/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0237 - acc: 0.9944 - val_loss: 3.1418 - val_acc: 0.6533\n",
            "Epoch 90/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0238 - acc: 0.9945 - val_loss: 3.1694 - val_acc: 0.6564\n",
            "Epoch 91/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0225 - acc: 0.9945 - val_loss: 3.1711 - val_acc: 0.6554\n",
            "Epoch 92/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0221 - acc: 0.9946 - val_loss: 3.1787 - val_acc: 0.6554\n",
            "Epoch 93/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0221 - acc: 0.9942 - val_loss: 3.1826 - val_acc: 0.6580\n",
            "Epoch 94/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0208 - acc: 0.9945 - val_loss: 3.1905 - val_acc: 0.6556\n",
            "Epoch 95/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0204 - acc: 0.9945 - val_loss: 3.1844 - val_acc: 0.6552\n",
            "Epoch 96/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0195 - acc: 0.9947 - val_loss: 3.1861 - val_acc: 0.6570\n",
            "Epoch 97/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0194 - acc: 0.9948 - val_loss: 3.2040 - val_acc: 0.6540\n",
            "Epoch 98/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0186 - acc: 0.9947 - val_loss: 3.2180 - val_acc: 0.6549\n",
            "Epoch 99/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0176 - acc: 0.9949 - val_loss: 3.2136 - val_acc: 0.6548\n",
            "Epoch 100/100\n",
            "2246/2246 [==============================] - 11s 5ms/step - loss: 0.0183 - acc: 0.9947 - val_loss: 3.2316 - val_acc: 0.6545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDCaDTUJi5e5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "53900300-3640-4965-884b-aba9c6613df9"
      },
      "source": [
        "# plot the results\n",
        "plt.plot(r.history['loss'],label='loss')\n",
        "plt.plot(r.history['val_loss'],label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(r.history['acc'],label='acc')\n",
        "plt.plot(r.history['val_acc'],label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRUQC6P8BDhMCEmYVyf8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJoxY6BtjTBix0DfGmDBioW+MMWHk/wOp4kwh7t+mZwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPC35tYpl0Oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Make predictions\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
        "\n",
        "# T=1 decoder model\n",
        "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM*2))\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRXpj1GZnwTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
        "decoder_lstm_input = context_last_word_concat_layer([context,decoder_inputs_single_x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wr-uGFfoV5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "o,s,c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s,initial_c])\n",
        "decoder_outputs = decoder_dense(o)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3JXMX35otjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_model = Model(inputs=[decoder_inputs_single,\n",
        "                              encoder_outputs_as_input,\n",
        "                              initial_s,\n",
        "                              initial_c],\n",
        "                      outputs=[decoder_outputs, s, c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktXoraJdpGvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# map indices back to real words\n",
        "idx2word_eng = {v:k for k,v in word2idx_inputs.items()}\n",
        "idx2word_trans = {v:k for k,v in word2idx_outputs.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ0bezeipmAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  enc_out = encoder_model.predict(input_seq)\n",
        "  \n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0,0] = word2idx_outputs['<sos>']\n",
        "  \n",
        "  eos = word2idx_outputs['<eos>']\n",
        "  \n",
        "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
        "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
        "  \n",
        "  # creating the translation\n",
        "  output_sentence = []\n",
        "  for _ in range(max_len_target):\n",
        "    o,s,c = decoder_model.predict([target_seq, enc_out, s, c])\n",
        "    \n",
        "    idx = np.argmax(o.flatten())\n",
        "    \n",
        "    if eos==idx:\n",
        "      break\n",
        "      \n",
        "    word = ''\n",
        "    \n",
        "    if idx>0:\n",
        "      word = idx2word_trans[idx]\n",
        "      output_sentence.append(word)\n",
        "    \n",
        "    target_seq[0,0] = idx\n",
        "  \n",
        "  return ' '.join(output_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2liYiYbGrNBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b7dd37ca-7a27-4342-e539-975e5ae152d9"
      },
      "source": [
        "i = np.random.choice(len(input_texts))\n",
        "input_seq = encoder_inputs[i:i+1]\n",
        "translation = decode_sequence(input_seq)\n",
        "print('Input Sentence:',input_texts[i])\n",
        "print('Predicted Translation:',translation)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Sentence: I have a headache.\n",
            "Predicted Translation: मेरे सिर में दर्द हो रहा है।\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}