{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_advNLP",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLQQ-WLfTRzB",
        "colab_type": "text"
      },
      "source": [
        "### Twitter ChatBot using Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkYJ5snBS2cE",
        "colab_type": "code",
        "outputId": "462cbb77-ba3b-4e02-bb30-abe7c402dfbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras.layers import (Input,LSTM,GRU,Dense,\n",
        "                          Embedding,Bidirectional,RepeatVector,\n",
        "                          Concatenate,Activation,Dot,Lambda)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras.backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U375mCZTTX-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to do softmax over time\n",
        "def softmax_over_time(x):\n",
        "  assert(K.ndim(x) > 2)\n",
        "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
        "  s = K.sum(e, axis=1, keepdims=True)\n",
        "  return e/s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lHUQxAcUsYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# config variables\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "LATENT_DIM = 256\n",
        "LATENT_DIM_DECODER = 256\n",
        "NUM_SAMPLES = 10000\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da1kQMSZVQy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_texts = [] # sentence in original language\n",
        "target_texts = [] # sentence in target language\n",
        "target_texts_inputs = [] # sentence in target language offset by 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAOS5AsrVXIN",
        "colab_type": "code",
        "outputId": "2f88b86e-cd61-42f1-f4c6-26db27964d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# load in the data\n",
        "t = 0\n",
        "for line in open('twitter_tab_format.txt'):\n",
        "  t+=1\n",
        "  if t>NUM_SAMPLES:\n",
        "    break\n",
        "  # input and target are seperated by '\\t'\n",
        "  if '\\t' not in line:\n",
        "    continue\n",
        "  input_text, translation = line.split('\\t')\n",
        "  target_text = translation + ' <eos>'\n",
        "  target_text_input = '<sos> ' + translation\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "  target_texts_inputs.append(target_text_input)\n",
        "print('num samples:',len(input_texts))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples: 8490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSiCip5bVz-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer_inputs.fit_on_texts(input_texts)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_IvjfRyV_PJ",
        "colab_type": "code",
        "outputId": "7769496c-a3c3-43af-9f7b-511aef90026e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# word to index mapping for input language\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "print('Found %s unique input tokens.'%len(word2idx_inputs))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9908 unique input tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tf9YwGRWhkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# max length input seq\n",
        "max_len_input = max(len(s) for s in input_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYGKvDM7WCTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize the outputs\n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs)\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ic4lx7_WHWx",
        "colab_type": "code",
        "outputId": "b5c5e5c8-622f-415a-a0ff-e8cc8b90c5c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# word to index mapping for output language\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "print('Found %s unique output tokens.'%len(word2idx_outputs))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14710 unique output tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0QuvS2EWKNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words_output = len(word2idx_outputs)+1\n",
        "# max length output seq\n",
        "max_len_target = max(len(s) for s in target_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u69mBx5CWUfZ",
        "colab_type": "code",
        "outputId": "05dc9de5-2c0b-4819-dfc8-c85e33bfa386",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# padding the sequences\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
        "print('Encoder data shape:',encoder_inputs.shape)\n",
        "\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
        "print('Decoder data shape:',decoder_inputs.shape)\n",
        "\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder data shape: (8490, 34)\n",
            "Decoder data shape: (8490, 33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaBGBku0WbC9",
        "colab_type": "code",
        "outputId": "e2ede2da-0428-4b18-8981-92db07171166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-11 05:50:26--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-08-11 05:50:26--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-08-11 05:50:26--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  38.7MB/s    in 22s     \n",
            "\n",
            "2019-08-11 05:50:49 (36.7 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4iaFwxWWpUC",
        "colab_type": "code",
        "outputId": "cd5d8ec3-f997-487d-eaa5-ee8419cb8718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA0cyMi0WrMr",
        "colab_type": "code",
        "outputId": "deb0c3bf-7dec-46d9-d02b-30a8ef4eee10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# loading pre-trained word vectors\n",
        "word2vec = {}\n",
        "with open('glove.6B.%sd.txt'%EMBEDDING_DIM) as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:],dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.'%len(word2vec))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NromsHVNWtO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare embedding matrix\n",
        "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs)+1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word2idx_inputs.items():\n",
        "  if i < MAX_NUM_WORDS:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtseteWjWvRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating embedding layer\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_len_input,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytyd1E-5W-pM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_targets_one_hot = np.zeros((len(input_texts),\n",
        "                                   max_len_target,\n",
        "                                   num_words_output),dtype='float32')\n",
        "for i,d in enumerate(decoder_targets):\n",
        "  for t,word in enumerate(d):\n",
        "    decoder_targets_one_hot[i, t, word] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN-hJRNBXK55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model\n",
        "# setup the encoder\n",
        "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = Bidirectional(LSTM(LATENT_DIM, return_sequences=True, dropout=0.5))\n",
        "encoder_outputs = encoder(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArYt6BpJYDIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup the decoder\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
        "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k279HGgRYviP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Attention layer\n",
        "attn_repeat_layer = RepeatVector(max_len_input)\n",
        "attn_concat_layer = Concatenate(axis=-1)\n",
        "attn_dense1 = Dense(10, activation='tanh')\n",
        "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
        "attn_dot = Dot(axes=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOjtFMZkZfnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_step_attention(h, st_1):\n",
        "  # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
        "  # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
        " \n",
        "  # copy s(t-1) Tx times\n",
        "  # now shape = (Tx, LATENT_DIM_DECODER)\n",
        "  st_1 = attn_repeat_layer(st_1)\n",
        "\n",
        "  # Concatenate all h(t)'s with s(t-1)\n",
        "  # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
        "  x = attn_concat_layer([h, st_1])\n",
        "\n",
        "  # Neural net first layer\n",
        "  x = attn_dense1(x)\n",
        "\n",
        "  # Neural net second layer with special softmax over time\n",
        "  alphas = attn_dense2(x)\n",
        "\n",
        "  # \"Dot\" the alphas and the h's\n",
        "  # Remember a.dot(b) = sum over a[t] * b[t]\n",
        "  context = attn_dot([alphas, h])\n",
        "\n",
        "  return context"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZMlCt7LbK2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decoder after attention\n",
        "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auai03zdb_ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
        "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
        "context_last_word_concat_layer = Concatenate(axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KClaJ0HMcd6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# s, c will be re-assigned in each iteration of the loop\n",
        "s = initial_s\n",
        "c = initial_c\n",
        "\n",
        "# collect outputs in a list at first\n",
        "outputs = []\n",
        "for t in range(max_len_target): # Ty times\n",
        "  # get the context using attention\n",
        "  context = one_step_attention(encoder_outputs, s)\n",
        "\n",
        "  # we need a different layer for each time step\n",
        "  selector = Lambda(lambda x: x[:, t:t+1])\n",
        "  xt = selector(decoder_inputs_x)\n",
        "  \n",
        "  # combine \n",
        "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
        "\n",
        "  # pass the combined [context, last word] into the LSTM\n",
        "  # along with [s, c]\n",
        "  # get the new [s, c] and output\n",
        "  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
        "\n",
        "  # final dense layer to get next word prediction\n",
        "  decoder_outputs = decoder_dense(o)\n",
        "  outputs.append(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsGmlxp3d_95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'outputs' is now a list of length Ty\n",
        "# each element is of shape [batch_size, output_vocab_size]\n",
        "# therefore if we simply stack all the outputs into 1 tensor\n",
        "# it would be of shape TxNxD\n",
        "# we would like it to be of shape NxTxD\n",
        "\n",
        "# so we stack and transpose\n",
        "def stack_and_transpose(x):\n",
        "  x = K.stack(x)\n",
        "  x = K.permute_dimensions(x, pattern=(1, 0, 2))\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BamvKMJ1hh0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making it a layer\n",
        "stacker = Lambda(stack_and_transpose)\n",
        "outputs = stacker(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB1tfVUyhsin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the model\n",
        "model = Model(inputs=[encoder_inputs_placeholder,\n",
        "                      decoder_inputs_placeholder,\n",
        "                      initial_s,\n",
        "                      initial_c],\n",
        "              outputs=outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caxYrtTUh-i9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9IC1ildigpW",
        "colab_type": "code",
        "outputId": "596892a2-d578-44b7-d837-fba00d3b3ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "z = np.zeros((len(encoder_inputs), LATENT_DIM_DECODER)) # initial [s, c]\n",
        "r = model.fit(\n",
        "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0811 05:51:44.933322 139707741038464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6792 samples, validate on 1698 samples\n",
            "Epoch 1/100\n",
            "6792/6792 [==============================] - 87s 13ms/step - loss: 3.0437 - acc: 0.6590 - val_loss: 2.6211 - val_acc: 0.6495\n",
            "Epoch 2/100\n",
            "6792/6792 [==============================] - 58s 9ms/step - loss: 2.3126 - acc: 0.6971 - val_loss: 2.5146 - val_acc: 0.6830\n",
            "Epoch 3/100\n",
            "6792/6792 [==============================] - 58s 8ms/step - loss: 2.1893 - acc: 0.7059 - val_loss: 2.4055 - val_acc: 0.6892\n",
            "Epoch 4/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 2.1154 - acc: 0.7099 - val_loss: 2.3708 - val_acc: 0.6897\n",
            "Epoch 5/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 2.0628 - acc: 0.7128 - val_loss: 2.3622 - val_acc: 0.6918\n",
            "Epoch 6/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 2.0171 - acc: 0.7152 - val_loss: 2.3410 - val_acc: 0.6923\n",
            "Epoch 7/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.9743 - acc: 0.7173 - val_loss: 2.3487 - val_acc: 0.6936\n",
            "Epoch 8/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.9344 - acc: 0.7189 - val_loss: 2.3261 - val_acc: 0.6948\n",
            "Epoch 9/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.8949 - acc: 0.7206 - val_loss: 2.3266 - val_acc: 0.6940\n",
            "Epoch 10/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.8538 - acc: 0.7223 - val_loss: 2.3203 - val_acc: 0.6930\n",
            "Epoch 11/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.8126 - acc: 0.7238 - val_loss: 2.3172 - val_acc: 0.6949\n",
            "Epoch 12/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.7724 - acc: 0.7256 - val_loss: 2.3080 - val_acc: 0.6953\n",
            "Epoch 13/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.7310 - acc: 0.7280 - val_loss: 2.3139 - val_acc: 0.6933\n",
            "Epoch 14/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.6954 - acc: 0.7298 - val_loss: 2.3227 - val_acc: 0.6936\n",
            "Epoch 15/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.6634 - acc: 0.7323 - val_loss: 2.3281 - val_acc: 0.6931\n",
            "Epoch 16/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.6332 - acc: 0.7348 - val_loss: 2.3268 - val_acc: 0.6935\n",
            "Epoch 17/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.6039 - acc: 0.7376 - val_loss: 2.3190 - val_acc: 0.6937\n",
            "Epoch 18/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.5730 - acc: 0.7403 - val_loss: 2.3355 - val_acc: 0.6939\n",
            "Epoch 19/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.5456 - acc: 0.7429 - val_loss: 2.3344 - val_acc: 0.6936\n",
            "Epoch 20/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.5167 - acc: 0.7454 - val_loss: 2.3565 - val_acc: 0.6927\n",
            "Epoch 21/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.4869 - acc: 0.7488 - val_loss: 2.3491 - val_acc: 0.6937\n",
            "Epoch 22/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.4601 - acc: 0.7518 - val_loss: 2.3503 - val_acc: 0.6940\n",
            "Epoch 23/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.4302 - acc: 0.7554 - val_loss: 2.3597 - val_acc: 0.6950\n",
            "Epoch 24/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.4001 - acc: 0.7588 - val_loss: 2.3500 - val_acc: 0.6968\n",
            "Epoch 25/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.3701 - acc: 0.7621 - val_loss: 2.3658 - val_acc: 0.6964\n",
            "Epoch 26/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.3415 - acc: 0.7659 - val_loss: 2.3557 - val_acc: 0.6972\n",
            "Epoch 27/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.3161 - acc: 0.7684 - val_loss: 2.3686 - val_acc: 0.6978\n",
            "Epoch 28/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.2926 - acc: 0.7723 - val_loss: 2.3638 - val_acc: 0.6987\n",
            "Epoch 29/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.2694 - acc: 0.7752 - val_loss: 2.3872 - val_acc: 0.6991\n",
            "Epoch 30/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.2463 - acc: 0.7783 - val_loss: 2.3876 - val_acc: 0.6982\n",
            "Epoch 31/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.2234 - acc: 0.7815 - val_loss: 2.3947 - val_acc: 0.6990\n",
            "Epoch 32/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.2002 - acc: 0.7846 - val_loss: 2.3963 - val_acc: 0.7002\n",
            "Epoch 33/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.1737 - acc: 0.7885 - val_loss: 2.3992 - val_acc: 0.7013\n",
            "Epoch 34/100\n",
            "6792/6792 [==============================] - 57s 8ms/step - loss: 1.1449 - acc: 0.7930 - val_loss: 2.4222 - val_acc: 0.7009\n",
            "Epoch 35/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.1232 - acc: 0.7960 - val_loss: 2.4257 - val_acc: 0.7018\n",
            "Epoch 36/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.1018 - acc: 0.7996 - val_loss: 2.4205 - val_acc: 0.7034\n",
            "Epoch 37/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.0738 - acc: 0.8041 - val_loss: 2.4420 - val_acc: 0.7025\n",
            "Epoch 38/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.0489 - acc: 0.8088 - val_loss: 2.4348 - val_acc: 0.7043\n",
            "Epoch 39/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.0277 - acc: 0.8122 - val_loss: 2.4377 - val_acc: 0.7052\n",
            "Epoch 40/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 1.0070 - acc: 0.8160 - val_loss: 2.4448 - val_acc: 0.7057\n",
            "Epoch 41/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.9903 - acc: 0.8187 - val_loss: 2.4497 - val_acc: 0.7067\n",
            "Epoch 42/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.9708 - acc: 0.8226 - val_loss: 2.4674 - val_acc: 0.7055\n",
            "Epoch 43/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.9546 - acc: 0.8248 - val_loss: 2.4679 - val_acc: 0.7071\n",
            "Epoch 44/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.9367 - acc: 0.8276 - val_loss: 2.4666 - val_acc: 0.7083\n",
            "Epoch 45/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.9195 - acc: 0.8312 - val_loss: 2.4725 - val_acc: 0.7074\n",
            "Epoch 46/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.8964 - acc: 0.8357 - val_loss: 2.4859 - val_acc: 0.7107\n",
            "Epoch 47/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.8739 - acc: 0.8401 - val_loss: 2.4866 - val_acc: 0.7107\n",
            "Epoch 48/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.8547 - acc: 0.8434 - val_loss: 2.4908 - val_acc: 0.7124\n",
            "Epoch 49/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.8366 - acc: 0.8473 - val_loss: 2.4913 - val_acc: 0.7118\n",
            "Epoch 50/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.8194 - acc: 0.8506 - val_loss: 2.5050 - val_acc: 0.7143\n",
            "Epoch 51/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.8031 - acc: 0.8537 - val_loss: 2.5032 - val_acc: 0.7143\n",
            "Epoch 52/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.7871 - acc: 0.8571 - val_loss: 2.5176 - val_acc: 0.7149\n",
            "Epoch 53/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.7713 - acc: 0.8604 - val_loss: 2.5207 - val_acc: 0.7147\n",
            "Epoch 54/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.7571 - acc: 0.8638 - val_loss: 2.5199 - val_acc: 0.7142\n",
            "Epoch 55/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.7402 - acc: 0.8670 - val_loss: 2.5207 - val_acc: 0.7165\n",
            "Epoch 56/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.7214 - acc: 0.8712 - val_loss: 2.5330 - val_acc: 0.7158\n",
            "Epoch 57/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.7068 - acc: 0.8743 - val_loss: 2.5285 - val_acc: 0.7165\n",
            "Epoch 58/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.6921 - acc: 0.8770 - val_loss: 2.5438 - val_acc: 0.7181\n",
            "Epoch 59/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.6793 - acc: 0.8795 - val_loss: 2.5411 - val_acc: 0.7176\n",
            "Epoch 60/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.6683 - acc: 0.8808 - val_loss: 2.5577 - val_acc: 0.7174\n",
            "Epoch 61/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.6553 - acc: 0.8841 - val_loss: 2.5428 - val_acc: 0.7202\n",
            "Epoch 62/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.6461 - acc: 0.8850 - val_loss: 2.5453 - val_acc: 0.7195\n",
            "Epoch 63/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.6326 - acc: 0.8888 - val_loss: 2.5582 - val_acc: 0.7200\n",
            "Epoch 64/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.6215 - acc: 0.8903 - val_loss: 2.5563 - val_acc: 0.7207\n",
            "Epoch 65/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.6099 - acc: 0.8925 - val_loss: 2.5622 - val_acc: 0.7212\n",
            "Epoch 66/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.5990 - acc: 0.8951 - val_loss: 2.5683 - val_acc: 0.7226\n",
            "Epoch 67/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.5861 - acc: 0.8978 - val_loss: 2.5724 - val_acc: 0.7220\n",
            "Epoch 68/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.5760 - acc: 0.9000 - val_loss: 2.5652 - val_acc: 0.7227\n",
            "Epoch 69/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.5651 - acc: 0.9018 - val_loss: 2.5821 - val_acc: 0.7231\n",
            "Epoch 70/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.5528 - acc: 0.9040 - val_loss: 2.5790 - val_acc: 0.7232\n",
            "Epoch 71/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.5428 - acc: 0.9059 - val_loss: 2.5770 - val_acc: 0.7242\n",
            "Epoch 72/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.5307 - acc: 0.9085 - val_loss: 2.5936 - val_acc: 0.7225\n",
            "Epoch 73/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.5199 - acc: 0.9106 - val_loss: 2.5901 - val_acc: 0.7244\n",
            "Epoch 74/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.5103 - acc: 0.9126 - val_loss: 2.5929 - val_acc: 0.7256\n",
            "Epoch 75/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.4988 - acc: 0.9151 - val_loss: 2.5982 - val_acc: 0.7251\n",
            "Epoch 76/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.4897 - acc: 0.9172 - val_loss: 2.6129 - val_acc: 0.7252\n",
            "Epoch 77/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.4773 - acc: 0.9198 - val_loss: 2.6091 - val_acc: 0.7263\n",
            "Epoch 78/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.4663 - acc: 0.9215 - val_loss: 2.6115 - val_acc: 0.7262\n",
            "Epoch 79/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.4523 - acc: 0.9248 - val_loss: 2.6140 - val_acc: 0.7265\n",
            "Epoch 80/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.4439 - acc: 0.9262 - val_loss: 2.6203 - val_acc: 0.7283\n",
            "Epoch 81/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.4319 - acc: 0.9289 - val_loss: 2.6347 - val_acc: 0.7277\n",
            "Epoch 82/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.4241 - acc: 0.9304 - val_loss: 2.6317 - val_acc: 0.7279\n",
            "Epoch 83/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.4144 - acc: 0.9320 - val_loss: 2.6372 - val_acc: 0.7287\n",
            "Epoch 84/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.4057 - acc: 0.9340 - val_loss: 2.6379 - val_acc: 0.7281\n",
            "Epoch 85/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3972 - acc: 0.9354 - val_loss: 2.6396 - val_acc: 0.7292\n",
            "Epoch 86/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3893 - acc: 0.9370 - val_loss: 2.6446 - val_acc: 0.7292\n",
            "Epoch 87/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3803 - acc: 0.9386 - val_loss: 2.6379 - val_acc: 0.7298\n",
            "Epoch 88/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3736 - acc: 0.9404 - val_loss: 2.6573 - val_acc: 0.7299\n",
            "Epoch 89/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3662 - acc: 0.9413 - val_loss: 2.6549 - val_acc: 0.7300\n",
            "Epoch 90/100\n",
            "6792/6792 [==============================] - 56s 8ms/step - loss: 0.3590 - acc: 0.9427 - val_loss: 2.6678 - val_acc: 0.7301\n",
            "Epoch 91/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3517 - acc: 0.9443 - val_loss: 2.6681 - val_acc: 0.7298\n",
            "Epoch 92/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3438 - acc: 0.9454 - val_loss: 2.6776 - val_acc: 0.7307\n",
            "Epoch 93/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3363 - acc: 0.9474 - val_loss: 2.6786 - val_acc: 0.7307\n",
            "Epoch 94/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3302 - acc: 0.9484 - val_loss: 2.6763 - val_acc: 0.7309\n",
            "Epoch 95/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3227 - acc: 0.9495 - val_loss: 2.6728 - val_acc: 0.7317\n",
            "Epoch 96/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3175 - acc: 0.9502 - val_loss: 2.6904 - val_acc: 0.7310\n",
            "Epoch 97/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3099 - acc: 0.9521 - val_loss: 2.6978 - val_acc: 0.7308\n",
            "Epoch 98/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.3031 - acc: 0.9531 - val_loss: 2.6991 - val_acc: 0.7318\n",
            "Epoch 99/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.2960 - acc: 0.9541 - val_loss: 2.7035 - val_acc: 0.7321\n",
            "Epoch 100/100\n",
            "6792/6792 [==============================] - 55s 8ms/step - loss: 0.2904 - acc: 0.9556 - val_loss: 2.7117 - val_acc: 0.7319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDCaDTUJi5e5",
        "colab_type": "code",
        "outputId": "759d4798-4a10-4114-d7fa-1ba17e05303b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "# plot the results\n",
        "plt.plot(r.history['loss'],label='loss')\n",
        "plt.plot(r.history['val_loss'],label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(r.history['acc'],label='acc')\n",
        "plt.plot(r.history['val_acc'],label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPC35tYpl0Oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Make predictions\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
        "\n",
        "# T=1 decoder model\n",
        "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM*2))\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRXpj1GZnwTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
        "decoder_lstm_input = context_last_word_concat_layer([context,decoder_inputs_single_x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wr-uGFfoV5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "o,s,c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s,initial_c])\n",
        "decoder_outputs = decoder_dense(o)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3JXMX35otjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_model = Model(inputs=[decoder_inputs_single,\n",
        "                              encoder_outputs_as_input,\n",
        "                              initial_s,\n",
        "                              initial_c],\n",
        "                      outputs=[decoder_outputs, s, c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktXoraJdpGvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# map indices back to real words\n",
        "idx2word_eng = {v:k for k,v in word2idx_inputs.items()}\n",
        "idx2word_trans = {v:k for k,v in word2idx_outputs.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ0bezeipmAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  enc_out = encoder_model.predict(input_seq)\n",
        "  \n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0,0] = word2idx_outputs['<sos>']\n",
        "  \n",
        "  eos = word2idx_outputs['<eos>']\n",
        "  \n",
        "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
        "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
        "  \n",
        "  # creating the translation\n",
        "  output_sentence = []\n",
        "  for _ in range(max_len_target):\n",
        "    o,s,c = decoder_model.predict([target_seq, enc_out, s, c])\n",
        "    \n",
        "    idx = np.argmax(o.flatten())\n",
        "    \n",
        "    if eos==idx:\n",
        "      break\n",
        "      \n",
        "    word = ''\n",
        "    \n",
        "    if idx>0:\n",
        "      word = idx2word_trans[idx]\n",
        "      output_sentence.append(word)\n",
        "    \n",
        "    target_seq[0,0] = idx\n",
        "  \n",
        "  return ' '.join(output_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2liYiYbGrNBE",
        "colab_type": "code",
        "outputId": "31baf1c0-52ff-4f30-efe9-60f07ba6e5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "i = np.random.choice(len(input_texts))\n",
        "input_seq = encoder_inputs[i:i+1]\n",
        "translation = decode_sequence(input_seq)\n",
        "print('Input Sentence:',input_texts[i])\n",
        "print('Predicted Translation:',translation)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Sentence: never thought i'd hear you say that since i feel you party all the time\n",
            "Predicted Translation: i do more than just party i actually live here...i have family here...i work a normal job here...it's not all partying\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HESZAGYEkxHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}